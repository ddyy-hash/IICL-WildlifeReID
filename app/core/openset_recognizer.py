#!/usr/bin/env python3
"""
å¼€æ”¾é›†è¯†åˆ«æœºåˆ¶
å®ç°åŠ¨æ€é˜ˆå€¼ç­–ç•¥ã€è´¨é‡æ‹’è¯†ã€ç›¸ä¼¼åº¦æ‹’è¯†å’Œä¸ç¡®å®šæ€§é‡åŒ–
"""

import torch
import torch.nn as nn
import torch.nn.functional as F 
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
import logging
from dataclasses import dataclass
import math


@dataclass
class OpenSetRecognitionResult:
    """å¼€æ”¾é›†è¯†åˆ«ç»“æœ"""
    is_known: bool  # æ˜¯å¦å±äºå·²çŸ¥ç±»åˆ«
    predicted_id: Optional[int]  # é¢„æµ‹çš„ç±»åˆ«IDï¼ˆå¦‚æœæ˜¯å·²çŸ¥ç±»åˆ«ï¼‰
    confidence: float  # ç½®ä¿¡åº¦
    uncertainty: float  # ä¸ç¡®å®šæ€§
    rejection_reason: Optional[str]  # æ‹’è¯†åŸå› ï¼ˆå¦‚æœè¢«æ‹’è¯†ï¼‰
    similarity_score: float  # ç›¸ä¼¼åº¦åˆ†æ•°
    quality_score: float  # è´¨é‡åˆ†æ•°


class QualityAssessor:
    """è´¨é‡è¯„ä¼°å™¨"""
    
    def __init__(self):
        # è´¨é‡è¯„ä¼°é˜ˆå€¼
        self.sharpness_threshold = 15.0
        self.contrast_threshold = 10.0
        self.brightness_min = 0.1
        self.brightness_max = 0.9
        
    def assess_quality(self, image: torch.Tensor) -> Dict[str, float]:
        """
        è¯„ä¼°å›¾åƒè´¨é‡
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W] æˆ– [B, C, H, W]
            
        Returns:
            è´¨é‡è¯„ä¼°ç»“æœ
        """
        # ç¡®ä¿è¾“å…¥æ˜¯4Då¼ é‡ [B, C, H, W]
        if image.dim() == 3:
            image = image.unsqueeze(0)
        
        B, C, H, W = image.shape
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if C == 3:
            gray_image = 0.299 * image[:, 0, :, :] + 0.587 * image[:, 1, :, :] + 0.114 * image[:, 2, :, :]
        else:
            gray_image = image[:, 0, :, :]
        
        # è®¡ç®—æ¸…æ™°åº¦ï¼ˆä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­ï¼‰
        laplacian = torch.tensor([[[[0, 1, 0], [1, -4, 1], [0, 1, 0]]]], dtype=torch.float32).to(image.device)
        laplacian = laplacian.expand(1, 1, 3, 3)
        
        sharpness_map = F.conv2d(gray_image.unsqueeze(1), laplacian, padding=1)
        sharpness = torch.mean(torch.abs(sharpness_map), dim=[1, 2, 3])
        
        # è®¡ç®—å¯¹æ¯”åº¦
        contrast = torch.std(gray_image, dim=[1, 2])
        
        # è®¡ç®—äº®åº¦
        brightness = torch.mean(gray_image, dim=[1, 2])
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        sharpness_score = torch.clamp(sharpness / self.sharpness_threshold, 0, 1)
        contrast_score = torch.clamp(contrast / self.contrast_threshold, 0, 1)
        brightness_score = torch.clamp(
            (brightness - self.brightness_min) / (self.brightness_max - self.brightness_min), 0, 1
        )
        
        # ç»¼åˆè´¨é‡åˆ†æ•°
        quality_score = (sharpness_score + contrast_score + brightness_score) / 3.0
        
        return {
            'sharpness': sharpness.mean().item(),
            'contrast': contrast.mean().item(),
            'brightness': brightness.mean().item(),
            'sharpness_score': sharpness_score.mean().item(),
            'contrast_score': contrast_score.mean().item(),
            'brightness_score': brightness_score.mean().item(),
            'quality_score': quality_score.mean().item()
        }


class DynamicThresholdStrategy:
    """
    åŠ¨æ€é˜ˆå€¼ç­–ç•¥ï¼ˆæ”¹è¿›ç‰ˆï¼šåŸºäºç‰¹å¾åˆ†å¸ƒçš„é˜ˆå€¼æ ‡å®šï¼‰
    
    æ”¹è¿›ç‚¹ï¼š
    1. é˜ˆå€¼åŸºäºå·²çŸ¥æ ·æœ¬çš„ç‰¹å¾åˆ†å¸ƒæ¥æ ‡å®šï¼Œè€Œéæ¨ç†ç»“æœ
    2. ä½¿ç”¨éªŒè¯é›†é¢„æ ‡å®šï¼Œé¿å…æ ‡ç­¾æ³„éœ²
    3. æ”¯æŒåŸºäºç»Ÿè®¡çš„è‡ªé€‚åº”è°ƒæ•´ï¼ˆä»…ä½¿ç”¨å·²çŸ¥æ ·æœ¬çš„åˆ†å¸ƒï¼‰
    """
    
    def __init__(self, initial_threshold: float = 0.7, adaptation_rate: float = 0.01,
                 percentile: float = 95.0):
        """
        åˆå§‹åŒ–åŠ¨æ€é˜ˆå€¼ç­–ç•¥
        
        Args:
            initial_threshold: åˆå§‹é˜ˆå€¼
            adaptation_rate: é˜ˆå€¼é€‚åº”ç‡
            percentile: ç”¨äºæ ‡å®šé˜ˆå€¼çš„ç™¾åˆ†ä½æ•°ï¼ˆåŸºäºå·²çŸ¥æ ·æœ¬å†…è·ç¦»åˆ†å¸ƒï¼‰
        """
        self.initial_threshold = initial_threshold
        self.adaptation_rate = adaptation_rate
        self.current_threshold = initial_threshold
        self.percentile = percentile
        
        # ã€æ”¹è¿›ã€‘ä»…å­˜å‚¨å·²çŸ¥æ ·æœ¬çš„ç±»å†…è·ç¦»ï¼Œç”¨äºé˜ˆå€¼æ ‡å®š
        self.intra_class_distances = []
        
        # ç»Ÿè®¡ä¿¡æ¯ï¼ˆä»…ç”¨äºç›‘æ§ï¼Œä¸ç”¨äºé˜ˆå€¼æ›´æ–°ï¼‰
        self.accepted_count = 0
        self.rejected_count = 0
        self.query_scores = []  # ä»…è®°å½•æŸ¥è¯¢åˆ†æ•°ï¼Œä¸åŒºåˆ†å·²çŸ¥/æœªçŸ¥
        
        # æ ‡å®šçŠ¶æ€
        self.is_calibrated = False
        self.calibrated_threshold = initial_threshold
        
    def calibrate_from_gallery(self, gallery_features: np.ndarray, gallery_labels: np.ndarray):
        """
        ã€æ–°å¢ã€‘ä½¿ç”¨å·²çŸ¥æ ·æœ¬åº“ï¼ˆgalleryï¼‰æ ‡å®šé˜ˆå€¼
        
        åŸºäºå·²çŸ¥æ ·æœ¬çš„ç±»å†…è·ç¦»åˆ†å¸ƒæ¥ç¡®å®šé˜ˆå€¼ï¼Œé¿å…æ ‡ç­¾æ³„éœ²
        
        Args:
            gallery_features: å·²çŸ¥æ ·æœ¬ç‰¹å¾ [N, D]
            gallery_labels: å·²çŸ¥æ ·æœ¬æ ‡ç­¾ [N]
        """
        if len(gallery_features) < 10:
            logging.warning("æ ·æœ¬æ•°é‡ä¸è¶³ï¼Œæ— æ³•æ ‡å®šé˜ˆå€¼")
            return
        
        # è®¡ç®—ç±»å†…è·ç¦»
        intra_distances = []
        unique_labels = np.unique(gallery_labels)
        
        for label in unique_labels:
            # è·å–åŒç±»æ ·æœ¬
            mask = gallery_labels == label
            class_features = gallery_features[mask]
            
            if len(class_features) < 2:
                continue
            
            # è®¡ç®—ç±»å†…æˆå¯¹è·ç¦»
            for i in range(len(class_features)):
                for j in range(i + 1, len(class_features)):
                    dist = np.linalg.norm(class_features[i] - class_features[j])
                    intra_distances.append(dist)
        
        if len(intra_distances) > 0:
            self.intra_class_distances = intra_distances
            # ä½¿ç”¨ç™¾åˆ†ä½æ•°ä½œä¸ºé˜ˆå€¼ï¼ˆç±»å†…è·ç¦»çš„ä¸Šç•Œï¼‰
            self.calibrated_threshold = np.percentile(intra_distances, self.percentile)
            self.current_threshold = self.calibrated_threshold
            self.is_calibrated = True
            logging.info(f"[OK] é˜ˆå€¼æ ‡å®šå®Œæˆ: {self.calibrated_threshold:.4f} "
                        f"(åŸºäº {len(intra_distances)} ä¸ªç±»å†…è·ç¦»å¯¹)")
    
    def update_threshold(self, similarity_scores: List[float], is_known: List[bool] = None):
        """
        æ›´æ–°é˜ˆå€¼ï¼ˆæ”¹è¿›ç‰ˆï¼šä»…åŸºäºæŸ¥è¯¢åˆ†æ•°åˆ†å¸ƒçš„ç»Ÿè®¡ç‰¹æ€§ï¼‰
        
        Args:
            similarity_scores: ç›¸ä¼¼åº¦åˆ†æ•°åˆ—è¡¨
            is_known: ã€åºŸå¼ƒã€‘ä¸å†ä½¿ç”¨æ­¤å‚æ•°ï¼Œä¿ç•™ä»…ä¸ºå…¼å®¹æ€§
        """
        # è®°å½•æŸ¥è¯¢åˆ†æ•°
        self.query_scores.extend(similarity_scores)
        
        # é™åˆ¶åˆ—è¡¨é•¿åº¦
        max_stats = 1000
        self.query_scores = self.query_scores[-max_stats:]
        
        # ã€æ”¹è¿›ã€‘å¦‚æœå·²æ ‡å®šï¼Œä»…åšè½»å¾®çš„è‡ªé€‚åº”è°ƒæ•´
        if self.is_calibrated and len(self.query_scores) > 50:
            # ä½¿ç”¨æŸ¥è¯¢åˆ†æ•°çš„åˆ†å¸ƒæ¥å¾®è°ƒï¼ˆä¸ä¾èµ–æ ‡ç­¾ï¼‰
            # å‡è®¾ï¼šå¤§éƒ¨åˆ†æŸ¥è¯¢åº”è¯¥æ˜¯å·²çŸ¥ç±»ï¼Œä½¿ç”¨ä¸­ä½æ•°ä½œä¸ºå‚è€ƒ
            median_score = np.median(self.query_scores[-50:])
            
            # ä»…åœ¨ä¸­ä½æ•°æ˜¾è‘—åç¦»æ ‡å®šé˜ˆå€¼æ—¶å¾®è°ƒ
            if abs(median_score - self.calibrated_threshold) > 0.1:
                # ä¿å®ˆè°ƒæ•´ï¼Œå‘æ ‡å®šé˜ˆå€¼é è¿‘
                self.current_threshold = (
                    self.current_threshold * (1 - self.adaptation_rate * 0.1) + 
                    self.calibrated_threshold * self.adaptation_rate * 0.1
                )
        
        # é™åˆ¶é˜ˆå€¼èŒƒå›´
        self.current_threshold = np.clip(self.current_threshold, 0.3, 0.95)
    
    def get_threshold(self) -> float:
        """è·å–å½“å‰é˜ˆå€¼"""
        return self.current_threshold
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'current_threshold': self.current_threshold,
            'calibrated_threshold': self.calibrated_threshold,
            'is_calibrated': self.is_calibrated,
            'accepted_count': self.accepted_count,
            'rejected_count': self.rejected_count,
            'mean_query_score': np.mean(self.query_scores) if self.query_scores else 0.0,
            'std_query_score': np.std(self.query_scores) if self.query_scores else 0.0,
            'num_intra_distances': len(self.intra_class_distances)
        }


class UncertaintyQuantifier:
    """ä¸ç¡®å®šæ€§é‡åŒ–å™¨"""
    
    def __init__(self, num_mc_samples: int = 10):
        """
        åˆå§‹åŒ–ä¸ç¡®å®šæ€§é‡åŒ–å™¨
        
        Args:
            num_mc_samples: Monte Carloé‡‡æ ·æ¬¡æ•°
        """
        self.num_mc_samples = num_mc_samples
        
    def quantify_uncertainty(
        self, 
        features: torch.Tensor, 
        feature_database: Any, 
        k: int = 5
    ) -> Dict[str, float]:
        """
        é‡åŒ–è¯†åˆ«ä¸ç¡®å®šæ€§
        
        Args:
            features: æŸ¥è¯¢ç‰¹å¾ [D] æˆ– [B, D]
            feature_database: ç‰¹å¾æ•°æ®åº“
            k: è€ƒè™‘çš„æœ€è¿‘é‚»æ•°é‡
            
        Returns:
            ä¸ç¡®å®šæ€§æŒ‡æ ‡
        """
        if features.dim() == 1:
            features = features.unsqueeze(0)
        
        # åœ¨ç‰¹å¾æ•°æ®åº“ä¸­æœç´¢
        similar_ids, distances = feature_database.search(features.cpu().numpy(), k=k)
        
        uncertainties = []
        
        for i, (neighbor_ids, dists) in enumerate(zip(similar_ids, distances)):
            if len(neighbor_ids) < 2:
                uncertainties.append(1.0)  # æœ€å¤§ä¸ç¡®å®šæ€§
                continue
            
            # è·å–é‚»å±…çš„ç±»åˆ«
            neighbor_classes = []
            for neighbor_id in neighbor_ids:
                result = feature_database.get_feature_by_id(neighbor_id)
                if result is not None:
                    _, metadata = result
                    neighbor_classes.append(metadata.get('dog_id', -1))
            
            if len(set(neighbor_classes)) <= 1:
                # æ‰€æœ‰é‚»å±…éƒ½æ˜¯åŒä¸€ç±»åˆ«ï¼Œä¸ç¡®å®šæ€§ä½
                uncertainty = 0.1
            else:
                # è®¡ç®—ç±»åˆ«åˆ†å¸ƒçš„ç†µ
                class_counts = {}
                for cls in neighbor_classes:
                    class_counts[cls] = class_counts.get(cls, 0) + 1
                
                # è®¡ç®—ç†µ
                total = sum(class_counts.values())
                entropy = 0.0
                for count in class_counts.values():
                    p = count / total
                    entropy -= p * math.log(p + 1e-10)
                
                # å½’ä¸€åŒ–ç†µ
                max_entropy = math.log(len(class_counts) + 1e-10)
                uncertainty = entropy / max_entropy if max_entropy > 0 else 0.0
            
            uncertainties.append(uncertainty)
        
        return {
            'uncertainty': np.mean(uncertainties),
            'uncertainty_std': np.std(uncertainties),
            'max_uncertainty': max(uncertainties),
            'min_uncertainty': min(uncertainties)
        }


class OpenSetRecognizer:
    """å¼€æ”¾é›†è¯†åˆ«å™¨"""
    
    def __init__(
        self,
        feature_database: Any,
        initial_threshold: float = 0.7,
        quality_threshold: float = 0.5,
        uncertainty_threshold: float = 0.6,
        adaptation_rate: float = 0.01
    ):
        """
        åˆå§‹åŒ–å¼€æ”¾é›†è¯†åˆ«å™¨
        
        Args:
            feature_database: ç‰¹å¾æ•°æ®åº“
            initial_threshold: åˆå§‹ç›¸ä¼¼åº¦é˜ˆå€¼
            quality_threshold: è´¨é‡é˜ˆå€¼
            uncertainty_threshold: ä¸ç¡®å®šæ€§é˜ˆå€¼
            adaptation_rate: é˜ˆå€¼é€‚åº”ç‡
        """
        self.feature_database = feature_database
        self.quality_threshold = quality_threshold
        self.uncertainty_threshold = uncertainty_threshold
        
        # è´¨é‡è¯„ä¼°å™¨
        self.quality_assessor = QualityAssessor()
        
        # åŠ¨æ€é˜ˆå€¼ç­–ç•¥
        self.threshold_strategy = DynamicThresholdStrategy(
            initial_threshold=initial_threshold,
            adaptation_rate=adaptation_rate
        )
        
        # ä¸ç¡®å®šæ€§é‡åŒ–å™¨
        self.uncertainty_quantifier = UncertaintyQuantifier(num_mc_samples=10)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.recognition_stats = {
            'total_queries': 0,
            'accepted_known': 0,
            'rejected_unknown': 0,
            'rejected_quality': 0,
            'rejected_uncertainty': 0
        }
        
        logging.info(f"[OK] å¼€æ”¾é›†è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ")
        logging.info(f"   åˆå§‹é˜ˆå€¼: {initial_threshold}")
        logging.info(f"   è´¨é‡é˜ˆå€¼: {quality_threshold}")
        logging.info(f"   ä¸ç¡®å®šæ€§é˜ˆå€¼: {uncertainty_threshold}")
    
    def recognize(
        self,
        query_features: torch.Tensor,
        query_image: Optional[torch.Tensor] = None,
        k: int = 5,
        return_details: bool = False
    ) -> OpenSetRecognitionResult:
        """
        æ‰§è¡Œå¼€æ”¾é›†è¯†åˆ«
        
        Args:
            query_features: æŸ¥è¯¢ç‰¹å¾ [D] æˆ– [1, D]
            query_image: æŸ¥è¯¢å›¾åƒï¼ˆç”¨äºè´¨é‡è¯„ä¼°ï¼‰
            k: æœ€è¿‘é‚»æ•°é‡
            return_details: æ˜¯å¦è¿”å›è¯¦ç»†ä¿¡æ¯
            
        Returns:
            å¼€æ”¾é›†è¯†åˆ«ç»“æœ
        """
        self.recognition_stats['total_queries'] += 1
        
        # ç¡®ä¿ç‰¹å¾æ˜¯ä¸€ç»´çš„
        if query_features.dim() > 1:
            query_features = query_features.squeeze()
        
        # 1. è´¨é‡è¯„ä¼°
        if query_image is not None:
            quality_result = self.quality_assessor.assess_quality(query_image)
            quality_score = quality_result['quality_score']
            
            if quality_score < self.quality_threshold:
                self.recognition_stats['rejected_quality'] += 1
                return OpenSetRecognitionResult(
                    is_known=False,
                    predicted_id=None,
                    confidence=0.0,
                    uncertainty=1.0,
                    rejection_reason=f"å›¾åƒè´¨é‡è¿‡ä½ (score: {quality_score:.3f})",
                    similarity_score=0.0,
                    quality_score=quality_score
                )
        else:
            quality_score = 1.0
        
        # 2. åœ¨ç‰¹å¾æ•°æ®åº“ä¸­æœç´¢
        similar_ids, distances = self.feature_database.search(
            query_features.cpu().numpy().reshape(1, -1), 
            k=k
        )
        
        if not similar_ids[0]:
            # æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼ç‰¹å¾
            self.recognition_stats['rejected_unknown'] += 1
            return OpenSetRecognitionResult(
                is_known=False,
                predicted_id=None,
                confidence=0.0,
                uncertainty=1.0,
                rejection_reason="æœªæ‰¾åˆ°ç›¸ä¼¼ç‰¹å¾",
                similarity_score=0.0,
                quality_score=quality_score
            )
        
        # 3. è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆå°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼‰
        similarity_scores = [1.0 / (1.0 + dist) for dist in distances[0]]
        max_similarity = max(similarity_scores)
        
        # 4. è·å–æœ€ç›¸ä¼¼ç‰¹å¾çš„ç±»åˆ«
        best_match_id = similar_ids[0][0]
        best_match_result = self.feature_database.get_feature_by_id(best_match_id)
        
        if best_match_result is None:
            self.recognition_stats['rejected_unknown'] += 1
            return OpenSetRecognitionResult(
                is_known=False,
                predicted_id=None,
                confidence=0.0,
                uncertainty=1.0,
                rejection_reason="æ— æ³•è·å–åŒ¹é…ç‰¹å¾",
                similarity_score=max_similarity,
                quality_score=quality_score
            )
        
        _, metadata = best_match_result
        predicted_id = metadata.get('dog_id', -1)
        
        # 5. é‡åŒ–ä¸ç¡®å®šæ€§
        uncertainty_result = self.uncertainty_quantifier.quantify_uncertainty(
            query_features, 
            self.feature_database, 
            k=k
        )
        uncertainty = uncertainty_result['uncertainty']
        
        # 6. è·å–åŠ¨æ€é˜ˆå€¼
        current_threshold = self.threshold_strategy.get_threshold()
        
        # 7. å†³ç­–
        is_known = True
        rejection_reason = None
        
        # æ£€æŸ¥ç›¸ä¼¼åº¦é˜ˆå€¼
        if max_similarity < current_threshold:
            is_known = False
            rejection_reason = f"ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼ ({max_similarity:.3f} < {current_threshold:.3f})"
        
        # æ£€æŸ¥ä¸ç¡®å®šæ€§é˜ˆå€¼
        elif uncertainty > self.uncertainty_threshold:
            is_known = False
            rejection_reason = f"ä¸ç¡®å®šæ€§è¿‡é«˜ ({uncertainty:.3f} > {self.uncertainty_threshold:.3f})"
        
        # æ›´æ–°ç»Ÿè®¡
        if is_known:
            self.recognition_stats['accepted_known'] += 1
        else:
            self.recognition_stats['rejected_unknown'] += 1
        
        # 8. æ›´æ–°åŠ¨æ€é˜ˆå€¼
        self.threshold_strategy.update_threshold([max_similarity], [is_known])
        
        # 9. è®¡ç®—ç½®ä¿¡åº¦
        if is_known:
            confidence = max_similarity * (1.0 - uncertainty) * quality_score
        else:
            confidence = 0.0
        
        return OpenSetRecognitionResult(
            is_known=is_known,
            predicted_id=predicted_id if is_known else None,
            confidence=confidence,
            uncertainty=uncertainty,
            rejection_reason=rejection_reason,
            similarity_score=max_similarity,
            quality_score=quality_score
        )
    
    def batch_recognize(
        self,
        query_features: torch.Tensor,
        query_images: Optional[torch.Tensor] = None,
        k: int = 5
    ) -> List[OpenSetRecognitionResult]:
        """
        æ‰¹é‡å¼€æ”¾é›†è¯†åˆ«
        
        Args:
            query_features: æŸ¥è¯¢ç‰¹å¾ [B, D]
            query_images: æŸ¥è¯¢å›¾åƒ [B, C, H, W]
            k: æœ€è¿‘é‚»æ•°é‡
            
        Returns:
            è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        results = []
        
        for i in range(query_features.shape[0]):
            feature = query_features[i]
            image = query_images[i] if query_images is not None else None
            
            result = self.recognize(feature, image, k=k)
            results.append(result)
        
        return results
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–è¯†åˆ«ç»Ÿè®¡ä¿¡æ¯"""
        threshold_stats = self.threshold_strategy.get_stats()
        
        return {
            **self.recognition_stats,
            'threshold_stats': threshold_stats,
            'acceptance_rate': (
                self.recognition_stats['accepted_known'] / 
                max(1, self.recognition_stats['total_queries'])
            ),
            'rejection_rate': (
                (self.recognition_stats['rejected_unknown'] + 
                 self.recognition_stats['rejected_quality']) / 
                max(1, self.recognition_stats['total_queries'])
            )
        }
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.recognition_stats = {
            'total_queries': 0,
            'accepted_known': 0,
            'rejected_unknown': 0,
            'rejected_quality': 0,
            'rejected_uncertainty': 0
        }
        self.threshold_strategy = DynamicThresholdStrategy(
            initial_threshold=self.threshold_strategy.initial_threshold,
            adaptation_rate=self.threshold_strategy.adaptation_rate
        )


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•å¼€æ”¾é›†è¯†åˆ«æœºåˆ¶")
    
    # åˆ›å»ºæ¨¡æ‹Ÿç‰¹å¾æ•°æ®åº“
    from app.core.feature_database import FeatureDatabase
    
    feature_db = FeatureDatabase(feature_dim=128, index_type="Flat")
    
    # æ·»åŠ å·²çŸ¥ç±»åˆ«çš„ç‰¹å¾
    known_features = torch.randn(50, 128)
    known_metadata = [{'dog_id': i // 10} for i in range(50)]  # 5ä¸ªç±»åˆ«ï¼Œæ¯ä¸ª10ä¸ªæ ·æœ¬
    
    feature_db.add_features(known_features.numpy(), known_metadata)
    
    print(f"[OK] ç‰¹å¾æ•°æ®åº“åˆ›å»ºå®Œæˆï¼Œç‰¹å¾æ•°: {feature_db.total_features}")
    
    # åˆ›å»ºå¼€æ”¾é›†è¯†åˆ«å™¨
    recognizer = OpenSetRecognizer(
        feature_database=feature_db,
        initial_threshold=0.6,
        quality_threshold=0.3,
        uncertainty_threshold=0.7,
        adaptation_rate=0.01
    )
    
    # æµ‹è¯•å·²çŸ¥ç±»åˆ«è¯†åˆ«
    print("\næµ‹è¯•å·²çŸ¥ç±»åˆ«è¯†åˆ«:")
    known_query = known_features[0]  # ä½¿ç”¨å·²çŸ¥ç‰¹å¾
    result = recognizer.recognize(known_query, k=5)
    
    print(f"  æ˜¯å¦å·²çŸ¥: {result.is_known}")
    print(f"  é¢„æµ‹ID: {result.predicted_id}")
    print(f"  ç½®ä¿¡åº¦: {result.confidence:.3f}")
    print(f"  ä¸ç¡®å®šæ€§: {result.uncertainty:.3f}")
    print(f"  ç›¸ä¼¼åº¦: {result.similarity_score:.3f}")
    
    # æµ‹è¯•æœªçŸ¥ç±»åˆ«è¯†åˆ«
    print("\næµ‹è¯•æœªçŸ¥ç±»åˆ«è¯†åˆ«:")
    unknown_query = torch.randn(128)  # éšæœºç‰¹å¾ï¼Œæ¨¡æ‹ŸæœªçŸ¥ç±»åˆ«
    result = recognizer.recognize(unknown_query, k=5)
    
    print(f"  æ˜¯å¦å·²çŸ¥: {result.is_known}")
    print(f"  æ‹’è¯†åŸå› : {result.rejection_reason}")
    print(f"  ç½®ä¿¡åº¦: {result.confidence:.3f}")
    print(f"  ä¸ç¡®å®šæ€§: {result.uncertainty:.3f}")
    
    # æµ‹è¯•è´¨é‡æ‹’è¯†
    print("\næµ‹è¯•è´¨é‡æ‹’è¯†:")
    # åˆ›å»ºä½è´¨é‡å›¾åƒï¼ˆéšæœºå™ªå£°ï¼‰
    low_quality_image = torch.rand(3, 64, 64) * 0.1
    result = recognizer.recognize(known_query, query_image=low_quality_image)
    
    print(f"  æ˜¯å¦å·²çŸ¥: {result.is_known}")
    print(f"  æ‹’è¯†åŸå› : {result.rejection_reason}")
    print(f"  è´¨é‡åˆ†æ•°: {result.quality_score:.3f}")
    
    # æ‰¹é‡æµ‹è¯•
    print("\næ‰¹é‡æµ‹è¯•:")
    batch_features = torch.cat([known_features[:3], torch.randn(2, 128)], dim=0)
    batch_results = recognizer.batch_recognize(batch_features)
    
    for i, result in enumerate(batch_results):
        print(f"  æ ·æœ¬ {i}: å·²çŸ¥={result.is_known}, ID={result.predicted_id}, ç½®ä¿¡åº¦={result.confidence:.3f}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("\nç»Ÿè®¡ä¿¡æ¯:")
    stats = recognizer.get_stats()
    print(f"  æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")
    print(f"  æ¥å—å·²çŸ¥: {stats['accepted_known']}")
    print(f"  æ‹’è¯†æœªçŸ¥: {stats['rejected_unknown']}")
    print(f"  æ‹’è¯†è´¨é‡: {stats['rejected_quality']}")
    print(f"  æ¥å—ç‡: {stats['acceptance_rate']:.3f}")
    print(f"  æ‹’è¯†ç‡: {stats['rejection_rate']:.3f}")
    
    print("ğŸ‰ å¼€æ”¾é›†è¯†åˆ«æœºåˆ¶æµ‹è¯•å®Œæˆ")
