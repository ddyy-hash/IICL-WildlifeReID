#!/usr/bin/env python3
"""
ç‰©ç†ä»¿çœŸå¢å¼ºæ¨¡å—
å®ç°å±€éƒ¨é˜´å½±ã€å¼ºå…‰/è¿‡æ›ã€è‰²æ¸©æ¼‚ç§»ã€é€†å…‰/å‰ªå½±ã€éšæœºé®æŒ¡ã€è¿åŠ¨æ¨¡ç³Šç­‰ç‰©ç†ä»¿çœŸæ•ˆæœ
"""

import torch
import torch.nn as nn
import numpy as np
import cv2
from typing import Tuple, Optional, List, Dict, Any
import random
from PIL import Image, ImageEnhance, ImageFilter


class PhysicalAugmentation:
    """ç‰©ç†ä»¿çœŸå¢å¼ºç±»"""
    
    def __init__(self, seed: Optional[int] = None):
        """
        åˆå§‹åŒ–ç‰©ç†ä»¿çœŸå¢å¼º
        
        Args:
            seed: éšæœºç§å­
        """
        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)
            torch.manual_seed(seed)
        
        # å¢å¼ºå¼ºåº¦å‚æ•°
        self.shadow_intensity_range = (0.3, 0.8)  # é˜´å½±å¼ºåº¦èŒƒå›´
        self.overexposure_threshold_range = (0.7, 0.9)  # è¿‡æ›é˜ˆå€¼èŒƒå›´
        self.color_temp_shift_range = (-1000, 1000)  # è‰²æ¸©æ¼‚ç§»èŒƒå›´ï¼ˆKï¼‰
        self.motion_blur_kernel_range = (5, 15)  # è¿åŠ¨æ¨¡ç³Šæ ¸å¤§å°èŒƒå›´
        self.occlusion_ratio_range = (0.1, 0.3)  # é®æŒ¡æ¯”ä¾‹èŒƒå›´
        
    def apply_local_shadow(
        self, 
        image: torch.Tensor, 
        shadow_intensity: Optional[float] = None,
        shadow_region: Optional[Tuple[int, int, int, int]] = None
    ) -> torch.Tensor:
        """
        åº”ç”¨å±€éƒ¨é˜´å½±
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W] æˆ– [B, C, H, W]
            shadow_intensity: é˜´å½±å¼ºåº¦ (0-1)ï¼Œå€¼è¶Šå¤§é˜´å½±è¶Šæš—
            shadow_region: é˜´å½±åŒºåŸŸ (x, y, w, h)ï¼Œå¦‚æœä¸ºNoneåˆ™éšæœºç”Ÿæˆ
            
        Returns:
            æ·»åŠ é˜´å½±åçš„å›¾åƒ
        """
        if shadow_intensity is None:
            shadow_intensity = random.uniform(*self.shadow_intensity_range)
        
        # ç¡®ä¿è¾“å…¥æ˜¯4Då¼ é‡ [B, C, H, W]
        is_single_image = image.dim() == 3
        if is_single_image:
            image = image.unsqueeze(0)
        
        B, C, H, W = image.shape
        
        # ç”Ÿæˆé˜´å½±åŒºåŸŸ
        if shadow_region is None:
            # éšæœºç”Ÿæˆé˜´å½±åŒºåŸŸï¼ˆè¦†ç›–20%-50%çš„å›¾åƒï¼‰
            region_w = random.randint(int(W * 0.2), int(W * 0.5))
            region_h = random.randint(int(H * 0.2), int(H * 0.5))
            region_x = random.randint(0, max(0, W - region_w))
            region_y = random.randint(0, max(0, H - region_h))
        else:
            region_x, region_y, region_w, region_h = shadow_region
        
        # åˆ›å»ºé˜´å½±æ©ç 
        shadow_mask = torch.ones_like(image)
        shadow_mask[:, :, region_y:region_y+region_h, region_x:region_x+region_w] = 1.0 - shadow_intensity
        
        # åº”ç”¨é˜´å½±
        shadowed_image = image * shadow_mask
        
        if is_single_image:
            shadowed_image = shadowed_image.squeeze(0)
        
        return shadowed_image
    
    def apply_overexposure(
        self, 
        image: torch.Tensor, 
        threshold: Optional[float] = None,
        overexposure_strength: Optional[float] = None
    ) -> torch.Tensor:
        """
        åº”ç”¨å¼ºå…‰/è¿‡æ›æ•ˆæœ
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W] æˆ– [B, C, H, W]
            threshold: è¿‡æ›é˜ˆå€¼ (0-1)ï¼Œé«˜äºæ­¤å€¼çš„åƒç´ ä¼šè¢«è¿‡æ›
            overexposure_strength: è¿‡æ›å¼ºåº¦ (0-1)
            
        Returns:
            æ·»åŠ è¿‡æ›æ•ˆæœçš„å›¾åƒ
        """
        if threshold is None:
            threshold = random.uniform(*self.overexposure_threshold_range)
        
        if overexposure_strength is None:
            overexposure_strength = random.uniform(0.5, 1.0)
        
        # ç¡®ä¿è¾“å…¥æ˜¯4Då¼ é‡ [B, C, H, W]
        is_single_image = image.dim() == 3
        if is_single_image:
            image = image.unsqueeze(0)
        
        # åˆ›å»ºè¿‡æ›æ©ç ï¼ˆé«˜äºé˜ˆå€¼çš„åŒºåŸŸï¼‰
        overexposure_mask = (image > threshold).float()
        
        # åº”ç”¨è¿‡æ›æ•ˆæœ
        overexposed_image = image.clone()
        overexposed_image = overexposed_image + overexposure_mask * overexposure_strength
        overexposed_image = torch.clamp(overexposed_image, 0.0, 1.0)
        
        if is_single_image:
            overexposed_image = overexposed_image.squeeze(0)
        
        return overexposed_image
    
    def apply_color_temperature_shift(
        self, 
        image: torch.Tensor, 
        temperature_shift: Optional[float] = None
    ) -> torch.Tensor:
        """
        åº”ç”¨è‰²æ¸©æ¼‚ç§»
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W] æˆ– [B, C, H, W]
            temperature_shift: è‰²æ¸©æ¼‚ç§»å€¼ï¼ˆæ­£æ•°ï¼šå˜æš–ï¼Œè´Ÿæ•°ï¼šå˜å†·ï¼‰
            
        Returns:
            è‰²æ¸©æ¼‚ç§»åçš„å›¾åƒ
        """
        if temperature_shift is None:
            temperature_shift = random.uniform(*self.color_temp_shift_range)
        
        # ç¡®ä¿è¾“å…¥æ˜¯4Då¼ é‡ [B, C, H, W]
        is_single_image = image.dim() == 3
        if is_single_image:
            image = image.unsqueeze(0)
        
        B, C, H, W = image.shape
        
        # è‰²æ¸©æ¼‚ç§»çŸ©é˜µï¼ˆç®€åŒ–ç‰ˆï¼‰
        # æš–è‰²æ¸©ï¼šå¢åŠ çº¢è‰²ï¼Œå‡å°‘è“è‰²
        # å†·è‰²æ¸©ï¼šå¢åŠ è“è‰²ï¼Œå‡å°‘çº¢è‰²
        if temperature_shift > 0:  # å˜æš–
            # çº¢è‰²é€šé“å¢å¼º
            red_factor = 1.0 + temperature_shift / 2000.0
            blue_factor = 1.0 - temperature_shift / 4000.0
        else:  # å˜å†·
            # è“è‰²é€šé“å¢å¼º
            red_factor = 1.0 + temperature_shift / 4000.0
            blue_factor = 1.0 - temperature_shift / 2000.0
        
        # åº”ç”¨è‰²æ¸©æ¼‚ç§»
        shifted_image = image.clone()
        shifted_image[:, 0, :, :] = shifted_image[:, 0, :, :] * red_factor   # Ré€šé“
        shifted_image[:, 2, :, :] = shifted_image[:, 2, :, :] * blue_factor  # Bé€šé“
        
        shifted_image = torch.clamp(shifted_image, 0.0, 1.0)
        
        if is_single_image:
            shifted_image = shifted_image.squeeze(0)
        
        return shifted_image
    
    def apply_backlight_silhouette(
        self, 
        image: torch.Tensor, 
        silhouette_strength: Optional[float] = None
    ) -> torch.Tensor:
        """
        åº”ç”¨é€†å…‰/å‰ªå½±æ•ˆæœ
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W] æˆ– [B, C, H, W]
            silhouette_strength: å‰ªå½±å¼ºåº¦ (0-1)ï¼Œå€¼è¶Šå¤§å‰ªå½±æ•ˆæœè¶Šæ˜æ˜¾
            
        Returns:
            æ·»åŠ å‰ªå½±æ•ˆæœçš„å›¾åƒ
        """
        if silhouette_strength is None:
            silhouette_strength = random.uniform(0.5, 0.9)
        
        # ç¡®ä¿è¾“å…¥æ˜¯4Då¼ é‡ [B, C, H, W]
        is_single_image = image.dim() == 3
        if is_single_image:
            image = image.unsqueeze(0)
        
        B, C, H, W = image.shape
        
        # åˆ›å»ºé€†å…‰æ•ˆæœï¼ˆè¾¹ç¼˜äº®ï¼Œä¸­å¿ƒæš—ï¼‰
        y_coords = torch.arange(H).float().to(image.device) / H
        x_coords = torch.arange(W).float().to(image.device) / W
        
        # åˆ›å»ºå¾„å‘æ¸å˜æ©ç 
        yy, xx = torch.meshgrid(y_coords, x_coords, indexing='ij')
        center_y, center_x = 0.5, 0.5
        distance_from_center = torch.sqrt((yy - center_y)**2 + (xx - center_x)**2)
        distance_from_center = distance_from_center / distance_from_center.max()
        
        # é€†å…‰æ©ç ï¼ˆè¾¹ç¼˜äº®ï¼Œä¸­å¿ƒæš—ï¼‰
        backlight_mask = 1.0 - distance_from_center * silhouette_strength
        
        # æ‰©å±•ç»´åº¦ä»¥åŒ¹é…å›¾åƒ
        backlight_mask = backlight_mask.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]
        backlight_mask = backlight_mask.expand(B, C, H, W)
        
        # åº”ç”¨é€†å…‰æ•ˆæœ
        backlit_image = image * backlight_mask
        
        if is_single_image:
            backlit_image = backlit_image.squeeze(0)
        
        return backlit_image
    
    def apply_motion_blur(
        self, 
        image: torch.Tensor, 
        kernel_size: Optional[int] = None,
        angle: Optional[float] = None
    ) -> torch.Tensor:
        """
        åº”ç”¨è¿åŠ¨æ¨¡ç³Š
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W] æˆ– [B, C, H, W]
            kernel_size: æ¨¡ç³Šæ ¸å¤§å°ï¼ˆå¥‡æ•°ï¼‰
            angle: è¿åŠ¨è§’åº¦ï¼ˆåº¦ï¼‰
            
        Returns:
            æ·»åŠ è¿åŠ¨æ¨¡ç³Šçš„å›¾åƒ
        """
        if kernel_size is None:
            kernel_size = random.randint(*self.motion_blur_kernel_range)
        
        if kernel_size % 2 == 0:
            kernel_size += 1  # ç¡®ä¿ä¸ºå¥‡æ•°
        
        if angle is None:
            angle = random.uniform(0, 360)
        
        # ç¡®ä¿è¾“å…¥æ˜¯4Då¼ é‡ [B, C, H, W]
        is_single_image = image.dim() == 3
        if is_single_image:
            image = image.unsqueeze(0)
        
        B, C, H, W = image.shape
        
        # åˆ›å»ºè¿åŠ¨æ¨¡ç³Šæ ¸
        kernel = torch.zeros((kernel_size, kernel_size), dtype=torch.float32)
        
        # è®¡ç®—è¿åŠ¨æ–¹å‘
        angle_rad = np.deg2rad(angle)
        center = kernel_size // 2
        
        # åœ¨ä¸­å¿ƒçº¿ä¸Šè®¾ç½®å€¼
        for i in range(kernel_size):
            x = i - center
            y = int(np.tan(angle_rad) * x)
            y_idx = center + y
            if 0 <= y_idx < kernel_size:
                kernel[y_idx, i] = 1.0
        
        # å½’ä¸€åŒ–
        kernel = kernel / kernel.sum()
        
        # æ‰©å±•ä¸ºå·ç§¯æ ¸ [out_channels, in_channels/groups, H, W]
        kernel = kernel.unsqueeze(0).unsqueeze(0)
        kernel = kernel.expand(C, 1, kernel_size, kernel_size).to(image.device)
        
        # åº”ç”¨è¿åŠ¨æ¨¡ç³Š
        blurred_image = F.conv2d(image, kernel, padding=kernel_size//2, groups=C)
        
        if is_single_image:
            blurred_image = blurred_image.squeeze(0)
        
        return blurred_image
    
    def apply_random_occlusion(
        self, 
        image: torch.Tensor, 
        occlusion_ratio: Optional[float] = None,
        occlusion_region: Optional[Tuple[int, int, int, int]] = None
    ) -> torch.Tensor:
        """
        åº”ç”¨éšæœºé®æŒ¡
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W] æˆ– [B, C, H, W]
            occlusion_ratio: é®æŒ¡åŒºåŸŸå å›¾åƒçš„æ¯”ä¾‹
            occlusion_region: é®æŒ¡åŒºåŸŸ (x, y, w, h)ï¼Œå¦‚æœä¸ºNoneåˆ™éšæœºç”Ÿæˆ
            
        Returns:
            æ·»åŠ é®æŒ¡åçš„å›¾åƒ
        """
        if occlusion_ratio is None:
            occlusion_ratio = random.uniform(*self.occlusion_ratio_range)
        
        # ç¡®ä¿è¾“å…¥æ˜¯4Då¼ é‡ [B, C, H, W]
        is_single_image = image.dim() == 3
        if is_single_image:
            image = image.unsqueeze(0)
        
        B, C, H, W = image.shape
        
        # è®¡ç®—é®æŒ¡åŒºåŸŸå¤§å°
        region_area = int(H * W * occlusion_ratio)
        region_w = int(np.sqrt(region_area * W / H))
        region_h = int(region_area / region_w)
        
        # ç”Ÿæˆé®æŒ¡åŒºåŸŸ
        if occlusion_region is None:
            region_x = random.randint(0, max(0, W - region_w))
            region_y = random.randint(0, max(0, H - region_h))
        else:
            region_x, region_y, region_w, region_h = occlusion_region
        
        # åº”ç”¨é®æŒ¡ï¼ˆå°†åŒºåŸŸç½®ä¸º0ï¼‰
        occluded_image = image.clone()
        occluded_image[:, :, region_y:region_y+region_h, region_x:region_x+region_w] = 0.0
        
        if is_single_image:
            occluded_image = occluded_image.squeeze(0)
        
        return occluded_image
    
    def apply_comprehensive_augmentation(
        self, 
        image: torch.Tensor, 
        augmentation_probs: Optional[Dict[str, float]] = None
    ) -> torch.Tensor:
        """
        åº”ç”¨ç»¼åˆç‰©ç†ä»¿çœŸå¢å¼º
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W] æˆ– [B, C, H, W]
            augmentation_probs: å„ç§å¢å¼ºçš„æ¦‚ç‡é…ç½®
            
        Returns:
            åº”ç”¨å¢å¼ºåçš„å›¾åƒ
        """
        if augmentation_probs is None:
            augmentation_probs = {
                'shadow': 0.3,
                'overexposure': 0.2,
                'color_temp_shift': 0.3,
                'backlight': 0.2,
                'motion_blur': 0.1,
                'occlusion': 0.2
            }
        
        augmented_image = image.clone()
        
        # å±€éƒ¨é˜´å½±
        if random.random() < augmentation_probs.get('shadow', 0.3):
            augmented_image = self.apply_local_shadow(augmented_image)
        
        # å¼ºå…‰/è¿‡æ›
        if random.random() < augmentation_probs.get('overexposure', 0.2):
            augmented_image = self.apply_overexposure(augmented_image)
        
        # è‰²æ¸©æ¼‚ç§»
        if random.random() < augmentation_probs.get('color_temp_shift', 0.3):
            augmented_image = self.apply_color_temperature_shift(augmented_image)
        
        # é€†å…‰/å‰ªå½±
        if random.random() < augmentation_probs.get('backlight', 0.2):
            augmented_image = self.apply_backlight_silhouette(augmented_image)
        
        # è¿åŠ¨æ¨¡ç³Š
        if random.random() < augmentation_probs.get('motion_blur', 0.1):
            augmented_image = self.apply_motion_blur(augmented_image)
        
        # éšæœºé®æŒ¡
        if random.random() < augmentation_probs.get('occlusion', 0.2):
            augmented_image = self.apply_random_occlusion(augmented_image)
        
        return augmented_image


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•ç‰©ç†ä»¿çœŸå¢å¼ºæ¨¡å—")
    
    # åˆ›å»ºå¢å¼ºå™¨
    augmentor = PhysicalAugmentation(seed=42)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = torch.rand(3, 256, 256)  # éšæœºå›¾åƒ
    
    print("æµ‹è¯•å„ç§å¢å¼ºæ•ˆæœï¼š")
    
    # æµ‹è¯•å±€éƒ¨é˜´å½±
    shadow_image = augmentor.apply_local_shadow(test_image, shadow_intensity=0.6)
    print(f"[OK] å±€éƒ¨é˜´å½±: {shadow_image.shape}, èŒƒå›´ [{shadow_image.min():.3f}, {shadow_image.max():.3f}]")
    
    # æµ‹è¯•è¿‡æ›
    overexposed_image = augmentor.apply_overexposure(test_image, threshold=0.7)
    print(f"[OK] å¼ºå…‰è¿‡æ›: {overexposed_image.shape}, èŒƒå›´ [{overexposed_image.min():.3f}, {overexposed_image.max():.3f}]")
    
    # æµ‹è¯•è‰²æ¸©æ¼‚ç§»
    warm_image = augmentor.apply_color_temperature_shift(test_image, temperature_shift=500)
    cold_image = augmentor.apply_color_temperature_shift(test_image, temperature_shift=-500)
    print(f"[OK] è‰²æ¸©æ¼‚ç§»ï¼ˆæš–ï¼‰: {warm_image.shape}")
    print(f"[OK] è‰²æ¸©æ¼‚ç§»ï¼ˆå†·ï¼‰: {cold_image.shape}")
    
    # æµ‹è¯•é€†å…‰
    backlit_image = augmentor.apply_backlight_silhouette(test_image, silhouette_strength=0.7)
    print(f"[OK] é€†å…‰å‰ªå½±: {backlit_image.shape}, èŒƒå›´ [{backlit_image.min():.3f}, {backlit_image.max():.3f}]")
    
    # æµ‹è¯•è¿åŠ¨æ¨¡ç³Š
    blurred_image = augmentor.apply_motion_blur(test_image, kernel_size=7, angle=45)
    print(f"[OK] è¿åŠ¨æ¨¡ç³Š: {blurred_image.shape}")
    
    # æµ‹è¯•é®æŒ¡
    occluded_image = augmentor.apply_random_occlusion(test_image, occlusion_ratio=0.2)
    print(f"[OK] éšæœºé®æŒ¡: {occluded_image.shape}, èŒƒå›´ [{occluded_image.min():.3f}, {occluded_image.max():.3f}]")
    
    # æµ‹è¯•ç»¼åˆå¢å¼º
    comprehensive_image = augmentor.apply_comprehensive_augmentation(test_image)
    print(f"[OK] ç»¼åˆå¢å¼º: {comprehensive_image.shape}, èŒƒå›´ [{comprehensive_image.min():.3f}, {comprehensive_image.max():.3f}]")
    
    # æ‰¹é‡æµ‹è¯•
    batch_image = torch.rand(4, 3, 256, 256)
    batch_augmented = augmentor.apply_comprehensive_augmentation(batch_image)
    print(f"[OK] æ‰¹é‡å¢å¼º: {batch_augmented.shape}")
    
    print("[OK] ç‰©ç†ä»¿çœŸå¢å¼ºæ¨¡å—æµ‹è¯•å®Œæˆ")